
    
! OpenMP support
    
!DIR$ IF DEFINED (_OPENMP)
  !DIR$ DEFINE CURR_OMP_VER = _OPENMP
!DIR$ ENDIF
    
!DIR$ IF DEFINED (CURR_OMP_VER) .OR. DEFINED (_OPENMP)
    !DIR$ DEFINE DERIVED_TYPE_HAS_ALLOCATABLES = 1
!DIR$ ENDIF

!Performance measurement

!DIR$ IF .NOT. DEFINED (USE_PROFILING)
    !DIR$ DEFINE USE_PROFILING = 1
!DIR$ ENDIF

!DIR$ IF DEFINED (USE_PROFILING)
   !DIR$ DEFINE USE_PREC_CLOCK = 1
!DIR$ ENDIF
    
!DIR$ IF DEFINED (USE_PROFILING)
    !DIR$ DEFINE USE_COARSE_CLOCK = 1
!DIR$ ENDIF
    
!DIR$ IF .NOT. DEFINED (PROFILE_SUBROUTINE_CALLS)
    !DIR$ DEFINE PROFILE_SUBROUTINE_CALLS = 1
!DIR$ ENDIF

! Optimization
    
!DIR$ IF .NOT. DEFINED (USE_AUTOVECTOR_DIRECTIVE)
    !DIR$ DEFINE USE_AUTOVECTOR_DIRECTIVE = 1
!DIR$ ENDIF
    
!DIR$ IF .NOT. DEFINED (USE_TRIP_COUNT_HINT)
    !DIR$ DEFINE USE_TRIP_COUNT_HINT = 1
!DIR$ ENDIF
    
!DIR$ IF .NOT. DEFINED (USE_SOFT_PREFETCH)
    !DIR$ DEFINE USE_SOFT_PREFETCH = 0
!DIR$ ENDIF
    
!DIR$ IF .NOT. DEFINED (USE_INLINING)
    !DIR$ DEFINE USE_INLINING = 1
!DIR$ ENDIF
    
!DIR$ IF .NOT. DEFINED (USE_VECTOR_REDUCTION)
    !DIR$ DEFINE USE_VECTOR_REDUCTION = 1
!DIR$ ENDIF
    
!DIR$ IF .NOT. DEFINED (USE_LOOP_UNROLLING)
    !DIR$ DEFINE USE_LOOP_UNROLLING = 1
!DIR$ ENDIF
    
!DIR$ IF DEFINED (USE_LOOP_UNROLLING) .AND. (USE_LOOP_UNROLLING) .EQ. 1
    !DIR$ DEFINE DEFAULT_UNROLL   = 2
    !DIR$ DEFINE MODERATE_UNROLL  = 4
    !DIR$ DEFINE AGGRESIVE_UNROLL = 8
    !DIR$ DEFINE MEMCPY_UNROLL    = 16
!DIR$ ENDIF
    
!DIR$ IF .NOT. DEFINED (USE_FORCEINLINE)
    !DIR$ DEFINE USE_FORCEINLINE = 0
!DIR$ ENDIF
    
!DIR$ IF .NOT. DEFINED (LOOP_DISTRIBUTE_POINT)
    !DIR$ DEFINE LOOP_DISTRIBUTE_POINT = 0
!DIR$ ENDIF
    
!DIR$ IF .NOT. DEFINED (LOOP_PARALLEL_ALWAYS)
    !DIR$ DEFINE LOOP_PARALLEL_ALWAYS = 0
!DIR$ ENDIF
    
!DIR$ IF .NOT. DEFINED (LOOP_UNROLL_AND_JAM)
    !DIR$ DEFINE LOOP_UNROLL_AND_JAM = 0
!DIR$ ENDIF
    
!DIR$ IF .NOT. DEFINED (LOOP_VECTORIZE_ALWAYS)
    !DIR$ DEFINE LOOP_VECTORIZE_ALWAYS = 0
!DIR$ ENDIF
    
!DIR$ IF .NOT. DEFINED (USE_IVDEP)
    !DIR$ DEFINE USE_IVDEP = 1
!DIR$ ENDIF
    
!DIR$ IF .NOT. DEFINED (USE_LOOP_BLOCKING)
    !DIR$ DEFINE USE_LOOP_BLOCKING = 0
!DIR$ ENDIF
    
!DIR$ IF .NOT. DEFINED (USE_LOOP_STRIP_MINING)
    !DIR$ DEFINE USE_LOOP_STRIP_MINING = 0
!DIR$ ENDIF
    
! Debugging
    
!DIR$ IF DEFINED (_DEBUG)
    !DIR$ DEFINE DEBUG_VERBOSE = 1
!DIR$ ENDIF
    
!DIR$ IF DEFINED (DEBUG_VERBOSE)  .AND. (DEBUG_VERBOSE .EQ. 1)
    !DIR$ DEFINE PRINT_CALLSTACK = 1
!DIR$ ENDIF
    
!DIR$ IF DEFINED (_DEBUG)
    !DIR$ CHECK_FP_CONSISTENCY = 1
!DIR$ ENDIF
    
!DIR$ IF .NOT. DEFINED (USE_LOGGING)
    !DIR$ DEFINE USE_LOGGING = 1
!DIR$ ENDIF
    
!DIR$ IF DEFINED (_DEBUG)
    !DIR$ DEFINE USE_CADNA_DIAGNOSTIC = 1
!DIR$ ENDIF
    
   ! Noisy on DEBUG build   
!DIR$ IF DEFINED (_DEBUG)
!DIR$ DEFINE IEEE_EXCEPT_FLAGS_NOISY = 1   
!DIR$ ENDIF

! Smith's algorithm for complex division.
#if !defined (USE_SAFE_COMPLEX_DIVISION)
    #define USE_SAFE_COMPLEX_DIVISION 1
#endif

! Use Intel Intrinsics C-wrapper for vector masked comparison
#if !defined (USE_INTRINSIC_VECTOR_COMPARE)
    #define USE_INTRINSIC_VECTOR_COMPARE 1
#endif


 !MKL
!DIR$ IF .NOT. DEFINED (HAVE_MKL)
    !DIR$ DEFINE HAVE_MKL = 1
!DIR$ ENDIF
    
!DIR$ IF .NOT. DEFINED (USE_STRUCT_PADDING)
    !DIR$ DEFINE USE_STRUCT_PADDING = 1
!DIR$ ENDIF
 
! Globally
!DIR$ IF .NOT. DEFINED (USE_IEEE_EXCEPTION_HANDLING)
    !DIR$ DEFINE USE_IEEE_EXCEPTION_HANDLING = 1
!DIR$ ENDIF 
    
!DIR$ IF .NOT. DEFINED (ADD_PADDING_VECTORIZE_REMAINDER)
    !DIR$ DEFINE ADD_PADDING_VECTORIZE_REMAINDER = 0
!DIR$ ENDIF
    
!DIR$ IF DEFINED (__INTEL_COMPILER)
    !DIR$ DEFINE GMS_COMPILED_BY = 1
!DIR$ ELSEIF DEFINED ( __GNUC__)
    !DIR$ DEFINE GMS_COMPILED_BY = 2
!DIR$ ELSE
    !DIR$ DEFINE GMS_COMPILED_BY = 3
!DIR$ ENDIF
    
!DIR$ IF (DEFINED (_M_AMD64) .OR. DEFINED (_M_X64_) .OR. DEFINED (__amd64)  .AND. .NOT. DEFINED (__x86_64__)
    !DIR$ DEFINE __x86_64__ = 1
!DIR$ ENDIF
    
!DIR$  (__X86_64__ .EQ.1) .AND. DEFINED (__AVX512F__)
    !DIR$ DEFINE GMS_COUNT_SIMD_REGISTERS = 32
!DIR$ ELSE
    !DIR$ DEFINE GMS_COUNT_SIMD_REGISTERS = 16
!DIR$ ENDIF
    
!DIR$ IF DEFINED (__AVX512F__)
    !DIR$ DEFINE GMS_HAS_AVX512F_ISA  = 1
!DIR$ ELSE
    !DIR$ DEFINE GMS_HAS_AVX512F_ISA = 0
!DIR$ ENDIF
    
!DIR$ IF DEFINED (__AVX512BW__)
    !DIR$ DEFINE GMS_HAS_AVX512BW_ISA  = 1
!DIR$ ELSE
    !DIR$ DEFINE GMS_HAS_AVX512BW_ISA = 0
!DIR$ ENDIF
    
!DIR$ IF DEFINED (__AVX512CD__)
    !DIR$ DEFINE GMS_HAS_AVX512CD_ISA  = 1
!DIR$ ELSE
    !DIR$ DEFINE GMS_HAS_AVX512CD_ISA = 0
!DIR$ ENDIF
    
!DIR$ IF DEFINED (__AVX512DQ__)
    !DIR$ DEFINE GMS_HAS_AVX512DQ_ISA  = 1
!DIR$ ELSE
    !DIR$ DEFINE GMS_HAS_AVX512DQ_ISA = 0
!DIR$ ENDIF
    
!DIR$ IF DEFINED (__AVX512ER__)
    !DIR$ DEFINE GMS_HAS_AVX512ER_ISA  = 1
!DIR$ ELSE
    !DIR$ DEFINE GMS_HAS_AVX512ER_ISA = 0
!DIR$ ENDIF
    
!DIR$ IF DEFINED (__AVX512PF__)
    !DIR$ DEFINE GMS_HAS_AVX512PF_ISA  = 1
!DIR$ ELSE
    !DIR$ DEFINE GMS_HAS_AVX512PF_ISA = 0
!DIR$ ENDIF
    
!DIR$ IF DEFINED (__AVX512VL__)
    !DIR$ DEFINE GMS_HAS_AVX512VL_ISA  = 1
!DIR$ ELSE
    !DIR$ DEFINE GMS_HAS_AVX512VL_ISA = 0
!DIR$ ENDIF
    
#ifndef CACHE_LINE_SIZE
#define CACHE_LINE_SIZE 64
#endif
    
#ifndef PAD_TO_CACHE_LINE
#define PAD_TO_CACHE_LINE(var_size) integer(kind=1), dimension(((CACHE_LINE_SIZE)-SIZEOF(var_size))) :: _pad_cache_line_
#endif

#ifndef PAD_TO
#define PAD_TO(ordinal,size) integer(kind=1), dimension((size)) :: pad##ordinal
#endif

#ifndef MSR_TOOLS_WRAPPERS_SHORT_VERSION
#define MSR_TOOLS_WRAPPERS_SHORT_VERSION 1
#endif

#ifndef ZEN_16_CORE
#define ZEN_16_CORE 0
#endif

#ifndef ZEN_24_CORE
#define ZEN_24_CORE 1
#endif

#ifndef ZEN_32_CORE
#define ZEN_32_CORE 0
#endif

!DIR$ IF .NOT. DEFINED (ADD_PADDING_FOR_LOOP_PEEL)
    !DIR$ DEFINE ADD_PADDING_FOR_LOOP_PEEL = 1
!DIR$ ENDIF

!DIR$ (ADD_PADDING_FOR_LOOP_PEEL .EQ.1)
  !DIR$ DEFINE LOOP_PEEL_PAD = 64
!DIR$ ENDIF

!DIR$ IF .NOT. DEFINED (USE_MANUAL_UNROLLING)
 !DIR$ DEFINE USE_MANUAL_UNROLLING = 0
!DIR$ ENDIF

!DIR$ IF (USE_MANUAL_UNROLLING .EQ. 1)
   !DIR$ DEFINE UNROLL_2X = 2
   !DIR$ DEFINE UNROLL_4X = 4
   !DIR$ DEFINE UNROLL_8X = 8
!DIR$ ELIF DEFINED (USE_MANUAL_UNROLLING) .AND. IF (__X86_64__ .EQ. 1)
   !DIR$ DEFINE UNROLL_16X = 16
   !DIR$ DEFINE UNROLL_32 = 32
!DIR$ ENDIF

!DIR$ IF .NOT. DEFINED (SHOW_CALLSTACK)
!DIR$ DEFINE SHOW_CALLSTACK = 1
!DIR$ ENDIF
     
   
!DIR$ IF .NOT. DEFINED (CUDA_GPU_LARGE_MEM_SPACE)
   !DIR$ DEFINE CUDA_GPU_LARGE_MEM_SPACE = 1
!DIR$ ENDIF

!DIR$ IF .NOT. DEFINED (USE_PERF_PROFILER)
   !DIR$ DEFINE USE_PERF_PROFILER = 0
!DIR$ ENDIF

!DIR$ IF .NOT. DEFINED (CPU_HASWELL)
   !DIR$ DEFINE CPU_HASWELL = 0
!DIR$ ENDIF

!DIR$ IF .NOT. DEFINED (CPU_ZEN)
   !DIR$ DEFINE CPU_ZEN = 0
!DIR$ ENDIF

    
    

    
    
    

    


    
